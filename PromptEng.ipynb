{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8V_rslKQ64d",
        "outputId": "c97ae336-6ce2-497a-f249-db4db66ebd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.28.0-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/320.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2Wwl6ksQctF"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key=\"------"\n",
        "client = openai.OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ],
      "metadata": {
        "id": "PpNOeYqzQmao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(10):\n",
        "    response = client.chat.completions.create(\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "        model=\"gpt-3.5-turbo\", # This is currently gpt-35-turbo\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Assistant provides single word answers.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What would be a programmers favorite Food? Give me the single food name only.\"}\n",
        "        ]\n",
        "    )\n",
        "    print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKU5CRZgRxKM",
        "outputId": "ba7197ae-7232-4ec8-a4d4-b3027a3d99e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n",
            "Pizza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHAT_MODEL =\"gpt-3.5-turbo\"\n",
        "def get_completion(prompt, model=CHAT_MODEL):\n",
        "    response = client.chat.completions.create(\n",
        "        temperature=0.2, # this is the degree of randomness of the model's output\n",
        "        model=\"gpt-3.5-turbo\", # This is currently gpt-35-turbo\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "fCFrPX-4SFuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampletext = \"\"\"Prompt engineering is a process in machine learning, specifically in Natural Language Processing (NLP),\n",
        "where prompts are designed to guide the model to provide the desired output. This technique is particularly used in transformer-based\n",
        "models like GPT-3. The quality of the prompt can significantly affect the model's performance. It involves crafting questions or statements\n",
        "in a way that helps the model understand the context and give relevant responses. It can be considered as a form of 'soft coding' to instruct\n",
        " an AI model.\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text between two lines of triple dashes into a single sentence.\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUYrTALJSRMc",
        "outputId": "4c1db74a-ae13-4501-ed65-55f4ecefef79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt engineering in machine learning, particularly in NLP, involves designing prompts to guide transformer-based models like GPT-3 for improved performance by helping the model understand context and provide relevant responses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Self check!"
      ],
      "metadata": {
        "id": "koJaxdP-Skyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampletext = \"1+1*2+3? equals what?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text between two lines of triple dashes into a single sentence. Say \"No Text Provided\" if there is no text between the triple dashes.\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DafTvZVjSgL3",
        "outputId": "5f200f65-385a-402c-eab9-4425ecab01bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Text Provided\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Few Shot Prompting"
      ],
      "metadata": {
        "id": "QLIuEomDSsv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Answer questions in a consistent style\n",
        "\n",
        "<q>: How can I learn to be a good programmer?\n",
        "<a>: In the realm of codes, where logic dances and sways,\n",
        "A quest to be a good programmer, you wish to pave your way.\n",
        "Fear not, for I shall guide you, in an enchanting lyrical play.\n",
        "\n",
        "Dive deep into the ocean of languages, where C++, Java, and Python lay,\n",
        "Choose your vessel wisely, let passion lead your way.\n",
        "\n",
        "<q>: How do I maximize my credit card rewards?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6vAjypaSubE",
        "outputId": "5b808a24-6917-4c88-fb54-c6690970c15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the realm of credit cards, where rewards gleam and sway,\n",
            "A quest to maximize, you wish to pave your way.\n",
            "Fear not, for I shall guide you, in an enchanting lyrical play.\n",
            "\n",
            "Understand your card's features, where points and cash back lay,\n",
            "Choose your spending wisely, let strategy lead your way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Time to think! / Chain-of-Thought (CoT) Prompting"
      ],
      "metadata": {
        "id": "GD9tlSFpTNEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "1+1+(2*2)=?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kD3SpRS92t",
        "outputId": "08568609-1784-4b2c-e946-73de81c84361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculation = f\"\"\"\n",
        "1+1+(2*2)=?\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Follow the steps below and provide your answer for each step\n",
        "1. Calculate the section between parantheses\n",
        "2. replace the paranteses with the result\n",
        "3. calculate the result\n",
        "\n",
        "---\n",
        "{calculation}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWjIX8wlTIsR",
        "outputId": "9e64ba46-53c4-4dac-ac87-f1fae7ad9253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Calculate the section between parentheses:\n",
            "2*2 = 4\n",
            "\n",
            "2. Replace the parentheses with the result:\n",
            "1+1+4 = 6\n",
            "\n",
            "3. Calculate the result:\n",
            "1+1+4 = 6\n",
            "\n",
            "Therefore, the result is 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hallucinations! Living in the dream world!"
      ],
      "metadata": {
        "id": "jMTr71UIT0LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is Daron As A Service offering from Microsoft?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7UWD-fYTiJ5",
        "outputId": "3d372cff-042f-4941-baf6-6f1a359d97a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daron As A Service (DAAS) is not a known offering from Microsoft. It is possible that you may have misspelled the service or it could be a new or niche service that is not widely recognized. If you have more information or context about DAAS, please provide it so I can assist you better.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?id=1uOVa1NYODk92xjqdt62OzPUO2sxy9Lch)\n",
        "\n"
      ],
      "metadata": {
        "id": "FHuWmsZnhQ_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Self Consistency"
      ],
      "metadata": {
        "id": "eVpYXA1OVHiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "When I was 12 my sister was half my age. Now\n",
        "I’m 70 how old is my sister?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeybEK9fTxbt",
        "outputId": "9d0f6a4b-72e5-43c4-c26a-7981af51f017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent $15. She has $8 left.\n",
        "Q: When I was 12 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avaUWqc9UZiT",
        "outputId": "4b9ab592-edea-450c-cab6-ee820fb91f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When you were 12, your sister was half your age, which means she was 6 years old at that time. The age difference between you and your sister is 6 years. Now that you are 70, your sister would be 70 - 6 = 64 years old.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generated Knowledge Prompting"
      ],
      "metadata": {
        "id": "cY9iBm-dVRMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Which country is larger, Congo or South Africa?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIWb1zrhVFLh",
        "outputId": "1d23511d-dc60-4e9b-b8a1-d3c9edfbd92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "South Africa is larger in terms of land area compared to Congo. South Africa has a total land area of approximately 1.22 million square kilometers, while Congo has a total land area of around 342,000 square kilometers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate some knowledge about the sizes of South Africa and Congo:\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfuL-oNDWDaz",
        "outputId": "8c600e04-4606-4a2e-c70e-e598596d9278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here is some information about the sizes of South Africa and Congo:\n",
            "\n",
            "1. South Africa:\n",
            "- South Africa is located in the southernmost part of the African continent.\n",
            "- It covers an area of approximately 1.22 million square kilometers (471,445 square miles).\n",
            "- South Africa is the 25th largest country in the world by land area.\n",
            "- The country has a diverse landscape that includes mountains, savannas, and coastal areas.\n",
            "\n",
            "2. Congo:\n",
            "- There are two countries in Africa with \"Congo\" in their names: the Republic of the Congo and the Democratic Republic of the Congo. I will provide information about both:\n",
            "  \n",
            "- Republic of the Congo:\n",
            "  - The Republic of the Congo is located in Central Africa.\n",
            "  - It covers an area of approximately 342,000 square kilometers (132,047 square miles).\n",
            "  - The Republic of the Congo is the 64th largest country in the world by land area.\n",
            "  - The country is known for its rainforests and wildlife, including lowland gorillas.\n",
            "\n",
            "- Democratic Republic of the Congo:\n",
            "  - The Democratic Republic of the Congo is also located in Central Africa.\n",
            "  - It is much larger than the Republic of the Congo, covering an area of approximately 2.34 million square kilometers (905,355 square miles).\n",
            "  - The Democratic Republic of the Congo is the 11th largest country in the world by land area.\n",
            "  - The country is rich in natural resources but has faced challenges such as political instability and conflict.\n",
            "\n",
            "These are just some basic facts about the sizes of South Africa, the Republic of the Congo, and the Democratic Republic of the Congo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "South Africa is a country located in the southernmost part of the African continent. It has a total land area of approximately 1,219,090 square kilometers, making it the 25th largest country in the world. South Africa is bordered by Namibia, Botswana, Zimbabwe, Mozambique, and Swaziland, and it has a coastline that stretches for 2,798 kilometers along the Atlantic and Indian Oceans.\n",
        "\n",
        "On the other hand, the Democratic Republic of Congo, also known as Congo-Kinshasa, is a country located in Central Africa. It has a total land area of approximately 2,344,858 square kilometers, making it the 11th largest country in the world. Congo is bordered by nine countries, including Angola, Zambia, Tanzania, and Uganda, and it has a coastline that stretches for 37 kilometers along the Atlantic Ocean.\n",
        "\n",
        "In terms of size, Congo is almost twice as large as South Africa. However, South Africa has a higher population density, with an estimated population of 59.3 million people compared to Congo's estimated population of 89.6 million people.\n",
        "\n",
        "Which country is larger, Congo or South Africa?\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU0HthiTWJkj",
        "outputId": "ab630415-1c3e-4506-c43a-bd671b957417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Democratic Republic of Congo (Congo) is larger in terms of land area compared to South Africa. Congo has a total land area of approximately 2,344,858 square kilometers, making it the 11th largest country in the world, while South Africa has a total land area of approximately 1,219,090 square kilometers, making it the 25th largest country in the world.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Imagine five different experts are answering this question.\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "Then all experts will go on to the next step, etc.\n",
        "If any expert realises they're wrong at any point then they leave.\n",
        "The question is...\n",
        "\n",
        "Which country is larger, Congo or South Africa?\n",
        "\n",
        "Give me a final conclusion.\n",
        "\"\"\"\n",
        "#Prompt reference: https://github.com/dave1010/tree-of-thought-prompting\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-ber0TmaDvW",
        "outputId": "7aed0e32-81da-4cc6-93d8-438715d0f6b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expert 1: First, I know that Congo is located in Central Africa and South Africa is located in the southern part of the continent.\n",
            "\n",
            "Expert 2: Next, I will recall that Congo is the larger of the two countries in terms of land area.\n",
            "\n",
            "Expert 3: Now, I will consider the specific land area of Congo, which is approximately 2.3 million square kilometers.\n",
            "\n",
            "Expert 4: Then, I will compare this to the land area of South Africa, which is around 1.2 million square kilometers.\n",
            "\n",
            "Expert 5: Finally, based on the land area comparison, I can confidently conclude that Congo is larger than South Africa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##summarization"
      ],
      "metadata": {
        "id": "SwMhwuZPWniu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampletext = \"During my trip to Ireland in May, I started feeling slightly unwell. I experienced symptoms such as a sore throat and a mild cough. Once I returned home, my condition significantly deteriorated. I developed fever and felt extremely unwell. I consulted a doctor, who prescribed antibiotics for me. Although I felt better for a few days, my health soon worsened again. After two visits to the emergency room, where I received IV fluids and medications, I gradually managed to recover. The diagnosis was a viral infection, and I was informed that it would likely take a couple of weeks to fully recuperate. Here we are, end of May, and I’m still not 100 percent back to normal. I’m still feeling tired.\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text between two lines of triple dashes in 20 words or less.\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f5eSEe1Wh4R",
        "outputId": "030647b9-ac0b-45d3-9b8e-3a63f854c535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traveler fell ill in Ireland, worsened upon return home. Diagnosed with viral infection, required hospital visits for recovery. Still fatigued.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extractive Summarization"
      ],
      "metadata": {
        "id": "sAjuK6qyXAAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampletext = \"During my trip to Ireland in May, I started feeling slightly unwell. I experienced symptoms such as a sore throat and a mild cough. Once I returned home, my condition significantly deteriorated. I developed fever and felt extremely unwell. I consulted a doctor, who prescribed antibiotics for me. Although I felt better for a few days, my health soon worsened again. After two visits to the emergency room, where I received IV fluids and medications, I gradually managed to recover. The diagnosis was a viral infection, and I was informed that it would likely take a couple of weeks to fully recuperate. Here we are, end of May, and I’m still not 100 percent back to normal. I’m still feeling tired.\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Extract relevant information from between two lines of triple dashes in 20 words or less. Focus on the travel aspect.\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdQCOdwFW97A",
        "outputId": "438defec-c52d-43de-d295-00969aa0896f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "During trip to Ireland in May, fell ill, worsened upon return. Diagnosed with viral infection, slow recovery, still fatigued.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment Analysis"
      ],
      "metadata": {
        "id": "kUocg-JkXe_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampletext = f\"\"\"I recently purchased the Stellaris Luminary LED Light Bulb and I must say, I'm completely blown away by its performance. This isn't your ordinary LED light bulb, it's a game changer!\n",
        "\n",
        "First of all, the brightness level this bulb produces is simply unparalleled. Whether you're using it for your reading room or simply as an overhead light in the living room, it illuminates the space with an impressive, crisp, and clear light. It's as if daylight has been captured and put inside a bulb! The adjustable brightness feature is also a nifty addition, allowing you to set the ambiance according to your mood.\n",
        "\n",
        "The energy efficiency of the Stellaris Luminary LED Light Bulb deserves a special mention. Despite its high brightness, it consumes significantly less power compared to traditional bulbs. This is a big plus for anyone looking to cut down on energy costs. Our monthly electricity bill has already shown a noticeable decrease, making this bulb a worthy investment.\n",
        "\n",
        "In terms of lifespan, the Stellaris Luminary outperforms every other light bulb I've ever used. It's been three months now and it's still shining as brightly as the day it was installed. The manufacturer promises a lifespan of 25,000 hours, and judging by its performance thus far, I have no reason to doubt this claim.\n",
        "\n",
        "The design of the bulb is sleek and modern, fitting in well with our home's contemporary decor. It's easy to install, and the customer service from Stellaris was top-notch when I had a query about the product.\n",
        "\n",
        "In conclusion, the Stellaris Luminary LED Light Bulb has exceeded my expectations in every aspect. It's bright, energy-efficient, long-lasting, and well-designed. It's more than just a light bulb, it's a smart investment for any household. I would highly recommend this product to anyone in search of a superior lighting solution.\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review,\n",
        "which is put between two lines of dashes?\n",
        "Give me your answer as a word.\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPTK8byJXQuO",
        "outputId": "e55149bd-c7b2-4b3a-dcb6-232afc46c239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Entity and Keyword Detection"
      ],
      "metadata": {
        "id": "peDcLi9FYhK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text which is put between two lines of dashes:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "Provide the list in a JSON.\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig-dBKH3Yi7I",
        "outputId": "0f1813a0-62a4-4bf6-e6c8-4ee53263c446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"Item purchased by reviewer\": \"Stellaris Luminary LED Light Bulb\",\n",
            "  \"Company that made the item\": \"Stellaris\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Intent Detection"
      ],
      "metadata": {
        "id": "sYKObgeyYuJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampletext = f\"\"\"Can I get a ticker to Paris from Istanbul airport for tomorrow 8AM?\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Consider the list of actions below\n",
        "- Book a flight\n",
        "- Rent a car\n",
        "- Buy a bus ticket\n",
        "\n",
        "Based on the following text given between two lines of ashes\n",
        "- which action is the user trying to perform?\n",
        "- extract keywords from the text that are relevant to the action\n",
        "- if found give a destination for the action\n",
        "- if found give a time for the action\n",
        "- if found give a date for the action. Today is Sep 8. 2023.\n",
        "- if found give a source for the action\n",
        "\n",
        "Provide your response in the form of a JSON object.\n",
        "\n",
        "---\n",
        "{sampletext}\n",
        "---\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlDJw72XYphK",
        "outputId": "396bcea0-7d20-43c1-a05b-518b5e7147ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "    \"action\": \"Book a flight\",\n",
            "    \"keywords\": [\"ticket\", \"Paris\", \"Istanbul airport\", \"tomorrow\", \"8AM\"],\n",
            "    \"destination\": \"Paris\",\n",
            "    \"time\": \"8AM\",\n",
            "    \"date\": \"Sep 9, 2023\",\n",
            "    \"source\": \"Istanbul airport\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spellcheck and Grammar Correction"
      ],
      "metadata": {
        "id": "5-8sVkjYZBwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dialog = f\"\"\"\n",
        "I doesnt likes to reading books becose it is to boring. My freind, they don't likes it to. We prefers to playing video games and watching moovies. Their is a new game that came's out yesterday, I wants to buy it soon.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Spellcheck the text between the dashed lines. Provide the correct spelling for any misspelled words.\n",
        "\n",
        "---\n",
        "{dialog}\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itIE0Xj2ZBmq",
        "outputId": "124313d2-c16e-49c2-c0d5-a020e0dac9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I doesn't like to reading books because it is too boring. My friend, they don't like it too. We prefer to playing video games and watching movies. There is a new game that came out yesterday, I want to buy it soon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REF : [Prompt Engineering'e Giriş](https://www.youtube.com/watch?v=R--fSB7CBIs&t=2951s)"
      ],
      "metadata": {
        "id": "7n3dZ7Q9t-0L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hn2fPNH_uRvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lQWFeuygZJTT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
